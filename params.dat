# Yahoo! Cloud System Benchmark
#   Default data size: 1 KB records (10 fields, 100 bytes each, plus key)

# A custom workload can be specified by following the formats shown below. By default workload A is set.
# Note: More information can be found here: (https://github.com/brianfrankcooper/YCSB/wiki/Core-Properties)
# and here (https://github.com/brianfrankcooper/YCSB/wiki/Running-a-Workload)

# Modify the number of worker threads 
threadcount=10

# Modify the number of items to insert in the workload
recordcount=10000
operationcount=10000

# This is the default workload config, don't change:
workload=com.yahoo.ycsb.workloads.CoreWorkload

# Workload A: (50% reads, 50% writes)
readallfields=true
readproportion=0.5
updateproportion=0.5
scanproportion=0
insertproportion=0
requestdistribution=zipfian


# Workload B (95% reads, 5% update, 0% insert): 
#readallfields=true
#readproportion=0.95
#updateproportion=0.05
#scanproportion=0
#insertproportion=0
#requestdistribution=zipfian


# Workload C (100% reads, 0% writes, 0% insert):
#readallfields=true
#readproportion=1
#updateproportion=0
#scanproportion=0
#insertproportion=0
#requestdistribution=zipfian

	# The insert order for this is hashed, not ordered. The "latest" items may be 
	# scattered around the keyspace if they are keyed by userid.timestamp. A workload
	# which orders items purely by time, and demands the latest, is very different than 
	# workload here (which we believe is more typical of how people build systems.)
# Workload D (95% reads, 0% writes, 5% insert):
#readallfields=true
#readproportion=0.95
#updateproportion=0
#scanproportion=0
#insertproportion=0.05
#requestdistribution=latest

	# The insert order is hashed, not ordered. Although the scans are ordered, it does not necessarily
	# follow that the data is inserted in order. For example, posts for thread 342 may not be inserted contiguously, but
	# instead interspersed with posts from lots of other threads. The way the YCSB client works is that it will pick a start
	# key, and then request a number of records; this works fine even for hashed insertion.
# Workload E (95% scan, 5% insert):
#readallfields=true
#readproportion=0
#updateproportion=0
#scanproportion=0.95
#insertproportion=0.05
#requestdistribution=zipfian
#maxscanlength=100
#scanlengthdistribution=uniform

# Workload F (50% read, 50% read-modfiy-write)
#readallfields=true
#readproportion=0.5
#updateproportion=0
#scanproportion=0
#insertproportion=0
#readmodifywriteproportion=0.5
#requestdistribution=zipfian


# Change inserts to updates to avoid duplicate key exceptions:
mongodb.upsert=true

# Set the url to the primary (port 27017), and include which replica set:
mongodb.url=mongodb://localhost:27017/?replicaSet=rs0










